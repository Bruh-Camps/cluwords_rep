{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacymoji.Emoji at 0x7f19c624d810>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"emoji\", first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"../data/queries_dev_train.csv\"\n",
    "\n",
    "data = pd.read_csv(data_source)\n",
    "\n",
    "data['text'] = data['text'].apply(lambda text: [word for word in nlp(text)])\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Goldfish,\n",
       "  Only,\n",
       "  Grow,\n",
       "  to,\n",
       "  the,\n",
       "  Size,\n",
       "  of,\n",
       "  Their,\n",
       "  Enclosure,\n",
       "  .,\n",
       "  There,\n",
       "  is,\n",
       "  an,\n",
       "  element,\n",
       "  of,\n",
       "  truth,\n",
       "  to,\n",
       "  this,\n",
       "  ,,\n",
       "  but,\n",
       "  it,\n",
       "  is,\n",
       "  not,\n",
       "  as,\n",
       "  innocent,\n",
       "  as,\n",
       "  it,\n",
       "  sounds,\n",
       "  and,\n",
       "  is,\n",
       "  related,\n",
       "  more,\n",
       "  to,\n",
       "  water,\n",
       "  quality,\n",
       "  than,\n",
       "  tank,\n",
       "  size,\n",
       "  .,\n",
       "  When,\n",
       "  properly,\n",
       "  cared,\n",
       "  for,\n",
       "  ,,\n",
       "  goldfish,\n",
       "  will,\n",
       "  not,\n",
       "  stop,\n",
       "  growing,\n",
       "  .,\n",
       "  Most,\n",
       "  fishes,\n",
       "  are,\n",
       "  in,\n",
       "  fact,\n",
       "  what,\n",
       "  are,\n",
       "  known,\n",
       "  as,\n",
       "  indeterminate,\n",
       "  growers,\n",
       "  .],\n",
       " [Depending,\n",
       "  on,\n",
       "  his,\n",
       "  type,\n",
       "  and,\n",
       "  his,\n",
       "  environment,\n",
       "  ,,\n",
       "  goldfish,\n",
       "  have,\n",
       "  the,\n",
       "  capacity,\n",
       "  to,\n",
       "  grow,\n",
       "  anywhere,\n",
       "  from,\n",
       "  around,\n",
       "  6,\n",
       "  to,\n",
       "  15,\n",
       "  inches,\n",
       "  within,\n",
       "  a,\n",
       "  very,\n",
       "  short,\n",
       "  period,\n",
       "  of,\n",
       "  time,\n",
       "  .,\n",
       "  If,\n",
       "  they,\n",
       "  are,\n",
       "  kept,\n",
       "  in,\n",
       "  tiny,\n",
       "  aquariums,\n",
       "  or,\n",
       "  little,\n",
       "  bowls,\n",
       "  ,,\n",
       "  they,\n",
       "  will,\n",
       "  still,\n",
       "  grow,\n",
       "  ,,\n",
       "  but,\n",
       "  much,\n",
       "  more,\n",
       "  slowly,\n",
       "  .,\n",
       "  Those,\n",
       "  conditions,\n",
       "  are,\n",
       "  somewhat,\n",
       "  cramped,\n",
       "  for,\n",
       "  the,\n",
       "  fish,\n",
       "  and,\n",
       "  that,\n",
       "  will,\n",
       "  show,\n",
       "  in,\n",
       "  ...]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data.text.to_list()\n",
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "for doc in texts:\n",
    "    for token in doc:\n",
    "        if token.pos_ not in (\"SYM\", \"PUNCT\", \"X\", \"NUM\"):\n",
    "            vocabulary.add(token.text.lower())\n",
    "\n",
    "vocabulary_pd = pd.Series(list(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10817,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      serious\n",
       "1      periods\n",
       "2     fumarate\n",
       "3    abundance\n",
       "4     analyzer\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vocabulary_pd.shape)\n",
    "vocabulary_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_pd.to_csv(\"../data/vocabulary_queries_dev_train.csv\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_pd = pd.read_csv(\"../data/vocabulary_queries_dev_train.csv\", names=[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jasper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-RN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>serious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>periods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fumarate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word\n",
       "0    Jasper\n",
       "1       -RN\n",
       "2   serious\n",
       "3   periods\n",
       "4  fumarate"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jasper'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_pd.word.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##################### Get vocabulary memory wise #############################\n",
    "##############################################################################\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load data from CSV files\n",
    "train_data = pd.read_csv(\"../data/queries/queries.train.tsv\", sep=\",\", header=None, names=[\"query_idx\", \"text\"])\n",
    "\n",
    "# Initialize a set to store the vocabulary\n",
    "vocabulary = set()\n",
    "\n",
    "# Process each text using spaCy\n",
    "for doc in nlp.pipe(data['text'], batch_size=3000, n_process=5):\n",
    "    for token in doc:\n",
    "        # Only include ____ tokens \n",
    "        if token.pos_ not in (\"SYM\", \"PUNCT\", \"X\", \"NUM\"):\n",
    "            vocabulary.add(token.text.lower())\n",
    "\n",
    "# Convert the set to a sorted list\n",
    "vocabulary = sorted(vocabulary)\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "vocabulary_df = pd.DataFrame(vocabulary, columns=[\"word\"])\n",
    "\n",
    "# Save the vocabulary to a CSV file\n",
    "output_dir = \"../data/\"\n",
    "output_file = os.path.join(output_dir, \"vocabulary_queries_dev_train.csv\")\n",
    "vocabulary_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Vocabulary saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cluwords-5TcCA87J-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
